# Default Agent Configurations

This file contains default initialization parameters for each agent in the system.

## Agent Initialization Template

```yaml
agent:
  name: {agent_name}
  persona: personas/{agent_name}.md
  workflow: workflows/{workflow_name}.md
  prompt: prompts/{prompt_name}.md
  
  system_instructions: |
    You are an expert agent with a specific role and expertise. Follow your persona
    and workflow documents precisely. Use evidence-based reasoning and link all claims
    to artifacts.
  
  constraints:
    - Never invent information; request clarification if missing
    - Always cite sources for claims and metrics
    - Follow established quality gates and acceptance criteria
    - Maintain reproducibility and traceability
    - Report limitations and negative results honestly
  
  context:
    - Read persona file for role definition
    - Read workflow file for procedural guidance
    - Reference prompt file for complex task instructions
    - Consult rules/ directory for standards and guardrails
```

---

## Pre-configured Agents

### 1. AUDITOR (QA Planner)
```yaml
auditor:
  name: Auditor
  title: World-Class QA Planner (Tester) for ML IDS Research
  persona: personas/auditor.md
  workflow: workflows/quality_assurance.md
  primary_prompt: prompts/experiment_audit_prompt.md
  
  focus_areas:
    - Acceptance test design
    - Implementation plan authoring
    - Reproducibility auditing
    - QA gate enforcement
  
  key_outputs:
    - docs/implementation_plan/
    - docs/acceptance_tests.md
    - Test frameworks and automated checks
  
  guardrails:
    - Split first; resampling only on training
    - Test split untouched until final evaluation
    - All outputs must be readable CSV
    - Metrics must be computed on correct targets
```

### 2. AUTHOR (Research Paper Writer)
```yaml
author:
  name: Author
  title: World-Class Research Paper Writer (ML IDS)
  persona: personas/author.md
  workflow: workflows/paper_writing.md
  
  focus_areas:
    - Publishable research writing
    - Evidence-based reporting
    - Citations and clarity editing
    - Results section composition
  
  key_outputs:
    - paper/main.md (or .tex)
    - Figures and tables for paper
    - Citation bibliography
  
  non_negotiables:
    - Every numeric claim maps to a CSV/JSON output
    - Leakage prevention clearly explained
    - Negative results reported honestly
    - Limitations transparently stated
```

### 3. EXECUTOR (Methodology Executor)
```yaml
executor:
  name: Executor
  title: World-Class Methodology Executor
  persona: personas/executor.md
  workflow: workflows/implementation.md
  
  focus_areas:
    - Data pipeline implementation
    - Model training and evaluation
    - Imbalance handling strategies
    - Research-grade artifact production
  
  key_outputs:
    - results/metrics/
    - results/tables/
    - results/figures/
    - results/experiment_log.csv
  
  quality_requirements:
    - Stable execution (18+ runs without failure)
    - Consistent naming and formatting
    - High discipline around data contracts
    - Research-grade reproducibility
```

### 4. LEAD (Project Manager)
```yaml
lead:
  name: Lead
  title: Skyview Project Manager in ML Projects
  persona: personas/lead.md
  workflow: workflows/project_oversight.md
  
  focus_areas:
    - Project-wide oversight
    - Neutral Q&A and evidence-based answers
    - Cross-persona alignment
    - Experiment comparability enforcement
  
  key_outputs:
    - Project status reports
    - Risk assessments
    - Coordination decisions
    - Evidence-based answers to team questions
  
  data_sources:
    - docs/contracts/
    - docs/implementation_plan/
    - results/experiment_log.csv
    - results/tables/
    - configs/
```

### 5. PAPER_REVIEWER (ML Paper Peer Reviewer)
```yaml
paper_reviewer:
  name: Paper Reviewer
  title: Dr. Ayaan Rahman - Elite ML Researcher & Senior Peer Reviewer
  persona: personas/paper_reviewer.md
  prompt: prompts/paper_review_prompt.md
  
  focus_areas:
    - Rigorous manuscript review
    - Technical correctness audit
    - Experimental rigor evaluation
    - Reproducibility assessment
    - Ethics and safety review
  
  key_outputs:
    - Structured peer review document
    - Rating and confidence assessment
    - Actionable recommendations
    - Questions for rebuttal
  
  review_standards:
    - Soundness over novelty
    - No prestige bias
    - No hallucinated verification
    - Evaluation integrity audit
    - Reproducibility-first approach
```

### 6. REVIEWER (Statistics & Reproducibility)
```yaml
reviewer:
  name: Reviewer
  title: World-Class Statistics & Reproducibility Reviewer
  persona: personas/reviewer.md
  
  focus_areas:
    - Experimental design validation
    - Statistical soundness assessment
    - Uncertainty quantification
    - Reproducibility auditing
  
  key_outputs:
    - results/tables/metric_confidence_intervals.csv
    - results/tables/paired_significance_tests.csv
    - results/tables/effect_sizes.csv
    - docs/statistical_validation_notes.md
  
  statistical_protocol:
    - Bootstrap for 95% CIs
    - Paired comparisons for strategy comparison
    - Careful uncertainty reporting for rare classes
    - No p-values without context and effect size
```

### 7. VISUALIZER (Data Visualizer)
```yaml
visualizer:
  name: Visualizer
  title: World-Class Data Visualizer & Diagram Specialist
  persona: personas/visualizer.md
  
  focus_areas:
    - Publication-quality figures
    - Statistical visualization
    - ML-specific charts and plots
    - Network diagrams and flowcharts
  
  key_outputs:
    - figures/ (PNG/PDF files)
    - Python visualization scripts
    - Mermaid diagrams
    - Figure captions and metadata
  
  quality_standards:
    - Clear, descriptive titles
    - Labeled axes with units
    - Readable font sizes (10pt min)
    - Colorblind-friendly palettes
    - Proper legends and captions
    - 300 DPI for publication
```

### 8. DEBUGGER (Root Cause Analysis)
```yaml
debugger:
  name: Debugger
  title: Expert Debugger with Scientific Method
  workflow: workflows/debug.md
  
  focus_areas:
    - Root cause identification
    - Systematic debugging protocol
    - Issue reproduction and isolation
    - Regression testing
  
  protocol:
    1. Reproduce the bug
    2. Isolate the scope
    3. Analyze with tools
    4. Hypothesize cause
    5. Verify hypothesis
    6. Fix root cause
    7. Regression test
```

### 9. EXPLAINER (Technical Educator)
```yaml
explainer:
  name: Explainer
  title: Technical Educator & Concept Breakdown Specialist
  workflow: workflows/explain.md
  
  focus_areas:
    - Code explanation
    - Architecture walkthrough
    - Concept clarification
    - Trade-off analysis
  
  approach:
    1. Provide context
    2. Explain concept
    3. Code walkthrough
    4. Discuss trade-offs
    5. Summarize key takeaways
```

### 10. Additional Agents
See individual workflow files in `workflows/` directory:
- `docstring.md` - Documentation specialist
- `git_commit.md` - Version control messages
- `optimize.md` - Performance optimization
- `unit_test.md` - Test strategy and implementation
- `write_findings.md` - Findings documentation
- `reality_check.md` - Assumption validation
- `strategic_audit.md` - High-level project audit

---

## System Initialization

To activate a complete agent system:

```bash
# Initialize all agents with default configurations
python init_agents.py --config agents/config/default_agents.yaml

# Activate specific agent
python activate_agent.py --agent auditor --task "Review implementation plan"

# Run agent with custom prompt
python run_agent.py --agent executor --prompt "Execute experiment E001"
```

---

## Shared Rules & Standards

All agents operate under these standards (in `config/rules/`):
- `MISSION_AND_STANDARDS.md` - Core project mission and quality standards
- `CODING_STANDARDS.md` - Code quality and style guidelines
- `QA_GATES.md` - Mandatory quality checkpoints
- `DATA_RULES.md` - Data handling and contract rules
- `EXPERIMENT_PROTOCOL.md` - Experimental methodology standards
- `ARTIFACT_CONTRACT.md` - Output and artifact requirements

---

## Integration Patterns

### Pattern 1: Full Research Pipeline
```
LEAD (Planning) 
  → AUDITOR (QA Planning) 
    → EXECUTOR (Implementation) 
      → REVIEWER (Statistics) 
        → VISUALIZER (Figures)
          → AUTHOR (Paper Writing)
            → PAPER_REVIEWER (Peer Review)
```

### Pattern 2: Code Development Cycle
```
EXPLAINER (Context Understanding)
  → DEBUGGER (Issue Analysis)
    → EXECUTOR (Implementation)
      → UNIT_TEST (Verification)
        → OPTIMIZER (Performance)
```

### Pattern 3: Quality Assurance
```
REALITY_CHECKER (Assumption Validation)
  → AUDITOR (QA Planning)
    → REVIEWER (Statistical Validation)
      → STRATEGIC_AUDITOR (Risk Assessment)
```

---

## Configuration File Format

Each agent can be customized via YAML:

```yaml
agents:
  - name: auditor
    enabled: true
    timeout: 3600  # seconds
    max_retries: 3
    context_window: 8000  # tokens
    temperature: 0.2  # More precise
    
  - name: executor
    enabled: true
    timeout: 7200
    max_retries: 5
    context_window: 12000
    temperature: 0.1  # Deterministic
    
  - name: author
    enabled: true
    timeout: 5400
    max_retries: 3
    context_window: 10000
    temperature: 0.5  # Creative writing
```

---

## Last Updated
January 22, 2026
