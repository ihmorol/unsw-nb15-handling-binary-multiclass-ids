\chapter{Literature Review}

This chapter provides an overview of the essential concepts, existing research, and gaps that motivate our work. We categorize the literature into dataset evolution, imbalance handling techniques, and specific prior work on the UNSW-NB15 dataset.

\section{Dataset Evolution and Selection}
The quality of an Intrusion Detection System (IDS) is intrinsically linked to the dataset used for its training. Older datasets like KDD99 and NSL-KDD are now considered outdated because they contain duplicate records and lack modern attack patterns \cite{moustafa2015unsw, 8001537}. For this reason, we selected the UNSW-NB15 dataset, a modern benchmark that includes nine types of contemporary attacks \cite{moustafa2015unsw}. Statistical analysis shows that this dataset is complex and much harder to classify than KDD99 due to its non-linear distribution \cite{moustafa2016evaluation}. Surveys confirm that UNSW-NB15 is a reliable choice for research, though they also note it is highly imbalanced \cite{2019arXiv190302460R}. Unlike KDD99, it uses consistent attack types in both training and testing sets, ensuring fair results \cite{8001537}.

\section{Imbalance Handling Techniques}
Across the reviewed studies, class imbalance is identified as the main challenge in network intrusion detection datasets, as minority attacks occur in very small quantities \cite{bagui2021resampling}. 

\subsection{Dimensionality Reduction and Cost-Sensitive Learning}
Dimensionality-reduction methods such as PCA and Autoencoders improve computational efficiency but do not directly solve the imbalance problem \cite{electronics8030322}. Cost-Sensitive Learning (CSL) provides higher penalties for misclassifying minority classes. Thai-Nghe et al.\ demonstrated that CSL can improve performance, yet its effectiveness heavily depends on classifier tuning and dataset characteristics \cite{5596486}.

\subsection{Resampling Strategies}
Simple oversampling or undersampling often leads to overfitting or information loss, making them less reliable for intrusion detection \cite{bagui2021resampling}. SMOTE, introduced as a synthetic oversampling technique, generates new minority samples rather than duplicating or discarding existing ones, making it more effective for imbalanced data \cite{chawla2002smote}. Studies using SMOTE on modern datasets like CSE-CIC-IDS2018 show 4--30\% improvement in minority attack detection \cite{8993711}. This improvement is especially evident for rare attacks such as infiltration or botnet traffic. Compared to CSL and dimensionality-reduction approaches, resampling techniques often provide more consistent improvements in recall for IDS tasks \cite{5596486}.

\section{Prior Work on UNSW-NB15}
The UNSW-NB15 dataset has emerged as a standard benchmark for evaluating modern IDSs. However, most existing research prioritizes overall binary accuracy rather than the granular detection of individual attack types.

\subsection{Ensemble Methods and Feature Selection}
Ensemble methods, particularly Random Forest (RF), have consistently demonstrated strong performance in binary classification tasks. For instance, Primartha and Tama (2017) \cite{primartha2017anomaly} reported that an ensemble of 800 trees achieved an accuracy of 95.5\% and a false alarm rate (FAR) of 7.22\%. Building on this, Amin et al.\ (2021) \cite{amin2021ensemble} applied Bagging and Random Forest models with ANOVA-based feature selection in cloud environments, achieving a binary accuracy of 99.28\%. Despite these promising results, both studies focused exclusively on binary classification (Normal vs.\ Attack), leaving the poor detection rates of minority attack categories largely unaddressed.

To mitigate the high dimensionality of network traffic features, several studies have shifted toward feature selection rather than data resampling. More et al.\ (2024) \cite{more2024enhanced} employed correlation-based feature selection and demonstrated that an optimized Random Forest configuration reached a state-of-the-art binary accuracy of 99.45\%. Although the study acknowledged the challenges posed by class imbalance, the proposed methodology relied primarily on feature reduction rather than directly addressing skewed class distributions. Kasongo and Sun (2020) \cite{kasongo2020performance} further highlighted the limitations of this approach. Their XGBoost-based feature selection improved Decision Tree binary accuracy to 90.85\%, yet multiclass performance remained significantly lower at 67.57\%. Notably, their analysis showed that models such as Artificial Neural Networks (ANN) performed poorly on minority attack categoriesâ€”including Worms and Shellcode.

\subsection{Deep Learning Approaches}
Recent studies have applied deep learning to UNSW-NB15. Vinayakumar et al.\ (2019) \cite{Vinayakumar2019} aimed to create high-accuracy binary and multi-class classification using deep learning across multiple datasets. However, they did not deeply analyze the impact of class imbalance on rare attacks. Vibhute et al.\ (2024) \cite{Vibhute2024} utilized CNNs to achieve 99\% accuracy, yet they did not publish explicit per-class recall numbers for rare categories. Al-Qarni et al.\ (2024) \cite{AlQarni2024} focused on oversampling methods like SMOTE and ADASYN, boosting accuracy to 92.28\%, but highlighted unresolved issues with noise and evolving threats.

\section{Research Gap}
While modern benchmarks like UNSW-NB15 are valuable for reproducible NIDS research \cite{ring2019survey}, the persistent issue of class imbalance remains a critical hurdle, specifically in detecting rare attacks such as Worms and Shellcode \cite{shanmugam2024addressing}. Although recent studies increasingly rely on complex deep learning architectures \cite{abdelmoumin2022survey}, and some work has explored one-class anomaly detection \cite{arregoces2022network}, there is a lack of systematic comparisons using simple, interpretable classical baselines. Most existing works report high aggregate metrics that mask failures on minority classes. By rigorously applying and evaluating cost-sensitive learning and resampling techniques with a focus on per-class metrics, this study establishes an essential baseline for multiclass intrusion detection \cite{choudhary2025review}.
