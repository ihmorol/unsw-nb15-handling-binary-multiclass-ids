\chapter{Literature Review}

This chapter provides an overview of the essential concepts, existing research, and gaps that motivate our work.\\

Older datasets like KDD99 and NSL-KDD are now considered outdated because they contain duplicate records and lack modern attack patterns \cite{moustafa2015unsw, 8001537}. For this reason, we selected the UNSW-NB15 dataset, a modern benchmark that includes nine types of contemporary attacks \cite{moustafa2015unsw}. Statistical analysis shows that this dataset is complex and much harder to classify than KDD99 due to its non-linear distribution \cite{moustafa2016evaluation}. Surveys confirm that UNSW-NB15 is a reliable choice for research, though they also note it is highly imbalanced \cite{2019arXiv190302460R}. Unlike KDD99, it uses consistent attack types in both training and testing sets, ensuring fair results \cite{8001537}. Recent studies indicate that because of this extreme imbalance, hybrid resampling is needed to detect minority attacks effectively \cite{bagui2021resampling}.\\


Across the reviewed studies, class imbalance is identified as the main challenge in network intrusion detection datasets, as minority attacks occur in very small quantities \cite{bagui2021resampling}. Dimensionality-reduction methods such as PCA and Autoencoders improve computational efficiency but do not directly solve the imbalance problem \cite{electronics8030322}. Cost-Sensitive Learning provides higher penalties for misclassifying minority classes, yet its performance heavily depends on classifier tuning and dataset characteristics \cite{5596486}. Simple oversampling or undersampling often leads to overfitting or information loss, making them less reliable for intrusion detection \cite{bagui2021resampling}. SMOTE, introduced as a synthetic oversampling technique, generates new minority samples rather than duplicating or discarding existing ones, making it more effective for imbalanced data \cite{chawla2002smote}. Studies using SMOTE on modern datasets like CSE-CIC-IDS2018 show 4–30 \% improvement in minority attack detection \cite{8993711}. This improvement is especially evident for rare attacks such as infiltration or botnet traffic \cite{8993711}. SMOTE also integrates well with a wide range of machine-learning models, including Random Forest, Gradient Boosting, and KNN \cite{8993711}. Compared to CSL and dimensionality-reduction approaches, SMOTE more consistently improves recall and balanced accuracy for IDS tasks \cite{5596486}. Overall, across all four papers, SMOTE stands out as the most effective method for handling data imbalance in intrusion detection systems \cite{chawla2002smote}.\\



The UNSW-NB15 dataset has emerged as a standard benchmark for evaluating modern Intrusion Detection Systems (IDS). However, most existing research prioritizes overall binary accuracy rather than the granular detection of individual attack types. Ensemble methods, particularly Random Forest (RF), have consistently demonstrated strong performance in binary classification tasks. For instance, Primartha and Tama(2017) \cite{primartha2017anomaly}  reported that an ensemble of 800 trees achieved an accuracy of 95.5\% and a false alarm rate (FAR) of 7.22\%. Building on this, Amin et al.(2021)\ \cite{amin2021ensemble}  applied Bagging and Random Forest models with ANOVA-based feature selection in cloud environments, achieving a binary accuracy of 99.28\%. Despite these promising results, both studies focused exclusively on binary classification (Normal vs.\ Attack), leaving the poor detection rates of minority attack categories largely unaddressed.

To mitigate the high dimensionality of network traffic features, several studies have shifted toward feature selection rather than data resampling. More et al.(2024)\ \cite{more2024enhanced}  employed correlation-based feature selection and demonstrated that an optimized Random Forest configuration reached a state-of-the-art binary accuracy of 99.45\%. Although the study acknowledged the challenges posed by class imbalance, the proposed methodology relied primarily on feature reduction rather than directly addressing skewed class distributions. Kasongo and Sun(2020) \cite{kasongo2020performance}  further highlighted the limitations of this approach. Their XGBoost-based feature selection improved Decision Tree binary accuracy to 90.85\%, yet multiclass performance remained significantly lower at 67.57\%. Notably, their analysis showed that models such as Artificial Neural Networks (ANN) performed poorly on minority attack categories—including Worms and Shellcode—and emphasized that future work should integrate synthetic oversampling techniques to enhance minority class detection.

Motivated by these gaps, the present study systematically investigates imbalance-handling strategies explicitly recommended in prior work, aiming to improve multiclass detection performance on the UNSW-NB15 dataset.\\


Vinayakumar et al. 2019\cite{Vinayakumar2019} goal is to create  Binary and Multi-class classification high accuracy. Resulting in  deep learning using many datasets including UNSW NB-15. But it did not  deeply analyze imbalanced class nor did show rare attacks. Vibhute et al. 2024 \cite{Vibhute2024} it aims to provide CNN feature and give results on accuracy 99\%, precision 99.03\% , recall 98.86\% , F-1 score 99\%  and show good architecture performance. It did not published explicit per rare attack recall numbers. Al-Qarni et al. 2024\cite{AlQarni2024} focus on oversampling methods like SMOTE and ADASYN using ML models and it boosted accuracy to ADASYN 92.28\% over SMOTE 88.13\%.Its limitation is oversampling and unsolved issues as noise and evolving threats. Syed Ibrahim Imtiaz 2022\cite{Imtiaz2022EfficientIoTAnomaly} its mainly Focus on binary anomaly vs normal classification by using the UNSW-NB15. DT and RF have 99\% accuracy. This  relies on the overall accuracy, which can be misleading when minority classes are rare.\\



Modern benchmarks dataset like UNSW-NB15 are highly valuable for reproducible NIDS research \cite{ring2019survey} but the persistent issue of class imbalance still remains to some extend, specially in detecting rare attacks such as worms and shellcode which continues to hinder the performance of contemporary intrusion detection systems \cite{shanmugam2024addressing}. Although recent studies increasingly rely on complex deep learning architectures \cite{abdelmoumin2022survey}, and some work has explored one-class anomaly detection \cite{arregoces2022network}, evidence suggests that applying targeted technical optimizations to classical machine learning models can still be highly effective. By rigorously applying and evaluating cost-sensitive learning and resampling techniques, this study establishes an essential baseline for multiclass intrusion detection\cite{choudhary2025review}.

