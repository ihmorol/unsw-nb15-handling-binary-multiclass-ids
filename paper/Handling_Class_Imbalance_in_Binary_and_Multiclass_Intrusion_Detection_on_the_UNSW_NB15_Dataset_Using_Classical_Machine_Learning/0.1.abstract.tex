%Abstract
\setlength{\headheight}{14pt}
\begin{center}
	{\huge \bf Abstract}
	\line(1,0){430}
\end{center}

Network Intrusion Detection Systems (NIDS) are essential for identifying malicious traffic, yet their performance on benchmark datasets such as UNSW-NB15 is often undermined by severe class imbalance. This imbalance causes machine learning models to exhibit high overall accuracy while failing to detect rare but critical attack types, including Worms, Shellcode, and Backdoors. In this study, we systematically investigate how class imbalance affects the detection capabilities of three classical machine learning models---Logistic Regression, Random Forest, and XGBoost---across both binary (Normal vs.\ Attack) and multiclass (ten-class) classification tasks. We evaluate three imbalance-handling strategies: no balancing (baseline), class weighting, and random oversampling. Our experiments, conducted on 18 configurations, reveal that while the baseline models achieve up to 76.9\% accuracy on multiclass classification, they completely fail to detect all four rare attack categories (0\% recall). In contrast, class weighting dramatically improves minority class detection, enabling XGBoost to achieve 84\% recall on Worms and 94\% recall on Shellcode, with an overall G-Mean of 0.795. For binary classification, XGBoost with class weighting achieves 90.8\% accuracy and 0.906 Macro-F1. These findings demonstrate that imbalance-handling strategies are essential for reliable intrusion detection and that aggregate accuracy metrics can be misleading when evaluating security-critical systems. We provide a reproducible baseline pipeline to support future research in this domain.

\clearpage
\setlength{\headheight}{12pt}