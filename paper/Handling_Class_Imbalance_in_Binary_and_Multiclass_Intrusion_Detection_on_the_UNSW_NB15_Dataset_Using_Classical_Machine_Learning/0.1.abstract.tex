%Abstract
\setlength{\headheight}{14pt}
\begin{center}
	{\huge \bf Abstract}
	\line(1,0){430}
\end{center}

Network Intrusion Detection Systems (NIDS) are critical for securing modern infrastructure, yet their efficacy is frequently compromised by extreme class imbalance. Benchmark datasets such as UNSW-NB15 contain attack categories like \textit{Worms} (0.07\% prevalence) that standard classifiers consistently ignore. In this study, we rigorously evaluate the impact of imbalance-handling strategies—Class Weighting (S1) and Random Oversampling (S2a)—on the detection of rare attacks using Logistic Regression, Random Forest, and XGBoost. Unlike prior works that rely on point-estimates of accuracy, we employ a robust statistical protocol involving \textbf{Friedman tests} and \textbf{Nemenyi post-hoc analysis} to validate performance rankings. Our results allow us to reject the null hypothesis ($p < 0.001$), demonstrating that cost-sensitive XGBoost (S1) provides a statistically significant improvement over baseline models. Specifically, S1 elevates \textit{Worms} detection from 0\% to a viable 66\% F1-score and achieves 94\% recall on \textit{Shellcode}. However, a deep forensic analysis reveals a ''Recall Cost'': the same strategy that captures \textit{Shellcode} introduces a false positive sink, reducing precision to 22\%. Furthermore, we uncover a topological feature overlap between \textit{Analysis} and \textit{Backdoor} vectors, demonstrating that standard flow features are insufficient for this distinction regardless of classifier complexity. We conclude that while algorithmic strategies can solve specific rarity challenges, others represent fundamental feature limitations that no amount of resampling can resolve.

\clearpage
\setlength{\headheight}{12pt}