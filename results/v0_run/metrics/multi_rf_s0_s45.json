{
  "experiment_id": "multi_rf_s0_s45",
  "seed": 45,
  "task": "multi",
  "model": "rf",
  "strategy": "s0",
  "timestamp": "2026-01-22T22:09:49.258790",
  "training_time_seconds": 22.884254932403564,
  "total_time_seconds": 27.093175172805786,
  "train_samples": 140272,
  "test_samples": 82332,
  "metrics": {
    "overall": {
      "accuracy": 0.7648909294077637,
      "macro_f1": 0.44797936284680145,
      "weighted_f1": 0.7715995983990425,
      "g_mean": 0.6818442768689114,
      "roc_auc": 0.9585935699819889
    },
    "per_class": {
      "Analysis": {
        "precision": 0.0026041666666666665,
        "recall": 0.0029542097488921715,
        "f1": 0.002768166089965398,
        "support": 677
      },
      "Backdoor": {
        "precision": 0.06164383561643835,
        "recall": 0.06174957118353345,
        "f1": 0.061696658097686374,
        "support": 583
      },
      "DoS": {
        "precision": 0.6964285714285714,
        "recall": 0.05722670579603815,
        "f1": 0.10576271186440678,
        "support": 4089
      },
      "Exploits": {
        "precision": 0.5641368550094729,
        "recall": 0.9094502335609055,
        "f1": 0.6963339982117065,
        "support": 11132
      },
      "Fuzzers": {
        "precision": 0.29278558801245896,
        "recall": 0.5737380402507424,
        "f1": 0.38771528900284263,
        "support": 6062
      },
      "Generic": {
        "precision": 0.999450065992081,
        "recall": 0.9630650204016745,
        "f1": 0.9809202536769667,
        "support": 18871
      },
      "Normal": {
        "precision": 0.9634499896458895,
        "recall": 0.7544594594594595,
        "f1": 0.8462424591505745,
        "support": 37000
      },
      "Reconnaissance": {
        "precision": 0.8943798449612403,
        "recall": 0.7920480549199085,
        "f1": 0.8401092233009708,
        "support": 3496
      },
      "Shellcode": {
        "precision": 0.42907801418439717,
        "recall": 0.6402116402116402,
        "f1": 0.5138004246284501,
        "support": 378
      },
      "Worms": {
        "precision": 1.0,
        "recall": 0.022727272727272728,
        "f1": 0.044444444444444446,
        "support": 44
      }
    },
    "confusion_matrix": [
      [
        2,
        8,
        8,
        630,
        21,
        0,
        8,
        0,
        0,
        0
      ],
      [
        2,
        36,
        9,
        507,
        25,
        0,
        1,
        0,
        3,
        0
      ],
      [
        210,
        238,
        234,
        3161,
        127,
        6,
        31,
        35,
        47,
        0
      ],
      [
        199,
        222,
        34,
        10124,
        288,
        2,
        91,
        117,
        55,
        0
      ],
      [
        30,
        45,
        19,
        1420,
        3478,
        1,
        907,
        73,
        89,
        0
      ],
      [
        0,
        4,
        21,
        583,
        67,
        18174,
        7,
        6,
        9,
        0
      ],
      [
        298,
        0,
        6,
        817,
        7776,
        0,
        27915,
        82,
        106,
        0
      ],
      [
        27,
        31,
        4,
        608,
        37,
        0,
        7,
        2769,
        13,
        0
      ],
      [
        0,
        0,
        1,
        59,
        56,
        0,
        6,
        14,
        242,
        0
      ],
      [
        0,
        0,
        0,
        37,
        4,
        1,
        1,
        0,
        0,
        1
      ]
    ]
  },
  "rare_class_analysis": {
    "Worms": {
      "precision": 1.0,
      "recall": 0.022727272727272728,
      "f1": 0.044444444444444446,
      "support": 44
    },
    "Shellcode": {
      "precision": 0.42907801418439717,
      "recall": 0.6402116402116402,
      "f1": 0.5138004246284501,
      "support": 378
    },
    "Backdoor": {
      "precision": 0.06164383561643835,
      "recall": 0.06174957118353345,
      "f1": 0.061696658097686374,
      "support": 583
    },
    "Analysis": {
      "precision": 0.0026041666666666665,
      "recall": 0.0029542097488921715,
      "f1": 0.002768166089965398,
      "support": 677
    }
  }
}